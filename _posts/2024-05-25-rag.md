---
layout: post
title: RAGï½œæµ‹è¯• çº¯æ‰‹å·¥æ­å»º RAG æ¡†æ¶ â€” Tiny RAG
categories: [RAG]
description: æµ‹è¯• çº¯æ‰‹å·¥æ­å»º RAG æ¡†æ¶ â€” Tiny RAG
keywords: RAG
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---

æµ‹è¯• çº¯æ‰‹å·¥æ­å»º RAG æ¡†æ¶ â€” Tiny RAGï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1. RAG ä»‹ç»ï¼›2. å‘é‡åŒ–ï¼›3. åŠ è½½å’Œåˆ‡åˆ†æ–‡æ¡£ï¼›4. æ•°æ®åº“å’Œå‘é‡æ£€ç´¢ï¼›5. å¤§æ¨¡å‹æ¨¡å—ï¼›6. ä»£ç å®ç°ï¼›7. RAGæ€»ç»“ç­‰æ–¹é¢ã€‚

#! https://zhuanlan.zhihu.com/p/698881085

# æµ‹è¯• çº¯æ‰‹å·¥æ­å»º RAG æ¡†æ¶ â€” Tiny RAG

ç›®å½•ï¼š
[toc]

Tiny-RAGï¼ŒåŒ…å«RAGçš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå³Retrievalå’ŒGenerationã€‚

æ„Ÿè°¢DataWhaleç»„ç»‡çš„å¤§æ¨¡å‹å®æˆ˜å­¦ä¹ ï¼Œå¯¹åº”çš„githubé“¾æ¥ ğŸ”—ï¼š[tiny-universe](https://github.com/datawhalechina/tiny-universe)

## 1. RAG ä»‹ç»

LLMä¼šäº§ç”Ÿè¯¯å¯¼æ€§çš„ â€œå¹»è§‰â€ï¼Œä¾èµ–çš„ä¿¡æ¯å¯èƒ½è¿‡æ—¶ï¼Œå¤„ç†ç‰¹å®šçŸ¥è¯†æ—¶æ•ˆç‡ä¸é«˜ï¼Œç¼ºä¹ä¸“ä¸šé¢†åŸŸçš„æ·±åº¦æ´å¯Ÿï¼ŒåŒæ—¶åœ¨æ¨ç†èƒ½åŠ›ä¸Šä¹Ÿæœ‰æ‰€æ¬ ç¼ºã€‚

æ­£æ˜¯åœ¨è¿™æ ·çš„èƒŒæ™¯ä¸‹ï¼Œæ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼ˆRetrieval-Augmented Generationï¼ŒRAGï¼‰åº”æ—¶è€Œç”Ÿï¼Œæˆä¸º AI æ—¶ä»£çš„ä¸€å¤§è¶‹åŠ¿ã€‚

RAG é€šè¿‡åœ¨è¯­è¨€æ¨¡å‹ç”Ÿæˆç­”æ¡ˆä¹‹å‰ï¼Œå…ˆä»å¹¿æ³›çš„æ–‡æ¡£æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç„¶ååˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œæå¤§åœ°æå‡äº†å†…å®¹çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§ã€‚RAG æœ‰æ•ˆåœ°ç¼“è§£äº†å¹»è§‰é—®é¢˜ï¼Œæé«˜äº†çŸ¥è¯†æ›´æ–°çš„é€Ÿåº¦ï¼Œå¹¶å¢å¼ºäº†å†…å®¹ç”Ÿæˆçš„å¯è¿½æº¯æ€§ï¼Œä½¿å¾—å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­å˜å¾—æ›´åŠ å®ç”¨å’Œå¯ä¿¡ã€‚

RAGçš„åŸºæœ¬ç»“æ„æœ‰å“ªäº›å‘¢ï¼Ÿ

- è¦æœ‰ä¸€ä¸ªå‘é‡åŒ–æ¨¡å—ï¼Œç”¨æ¥å°†æ–‡æ¡£ç‰‡æ®µå‘é‡åŒ–ã€‚
- è¦æœ‰ä¸€ä¸ªæ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†çš„æ¨¡å—ï¼Œç”¨æ¥åŠ è½½æ–‡æ¡£å¹¶åˆ‡åˆ†æˆæ–‡æ¡£ç‰‡æ®µã€‚
- è¦æœ‰ä¸€ä¸ªæ•°æ®åº“æ¥å­˜æ”¾æ–‡æ¡£ç‰‡æ®µå’Œå¯¹åº”çš„å‘é‡è¡¨ç¤ºã€‚
- è¦æœ‰ä¸€ä¸ªæ£€ç´¢æ¨¡å—ï¼Œç”¨æ¥æ ¹æ® Query ï¼ˆé—®é¢˜ï¼‰æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚
- è¦æœ‰ä¸€ä¸ªå¤§æ¨¡å‹æ¨¡å—ï¼Œç”¨æ¥æ ¹æ®æ£€ç´¢å‡ºæ¥çš„æ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚


![](https://cdn.jsdelivr.net/gh/HuZixia/CloudGo/pictures/resources/rag/Retrieval_Augmented_Generation_RAG_Learning.png)

RAG çš„æµç¨‹ï¼š

- **ç´¢å¼•**ï¼šå°†æ–‡æ¡£åº“åˆ†å‰²æˆè¾ƒçŸ­çš„ Chunkï¼Œå¹¶é€šè¿‡ç¼–ç å™¨æ„å»ºå‘é‡ç´¢å¼•ã€‚
- **æ£€ç´¢**ï¼šæ ¹æ®é—®é¢˜å’Œ chunks çš„ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µã€‚
- **ç”Ÿæˆ**ï¼šä»¥æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸ºæ¡ä»¶ï¼Œç”Ÿæˆé—®é¢˜çš„å›ç­”ã€‚

é‚£ä¹Ÿå°±æ˜¯ä¸‹å›¾æ‰€ç¤ºçš„æµç¨‹ï¼Œå›¾ç‰‡å‡ºå¤„ ***[Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/pdf/2312.10997.pdf)***

![](https://cdn.jsdelivr.net/gh/HuZixia/CloudGo/pictures/resources/rag/RAG.png)

## 2. å‘é‡åŒ–

é¦–å…ˆè®©æˆ‘ä»¬æ¥åŠ¨æ‰‹å®ç°ä¸€ä¸ªå‘é‡åŒ–çš„ç±»ï¼Œè¿™æ˜¯RAGæ¶æ„çš„åŸºç¡€ã€‚å‘é‡åŒ–çš„ç±»ä¸»è¦æ˜¯ç”¨æ¥å°†æ–‡æ¡£ç‰‡æ®µå‘é‡åŒ–ï¼Œå°†ä¸€æ®µæ–‡æœ¬æ˜ å°„ä¸ºä¸€ä¸ªå‘é‡ã€‚

é‚£é¦–å…ˆæˆ‘ä»¬è¦è®¾ç½®ä¸€ä¸ª `Embedding` åŸºç±»ï¼Œè¿™æ ·æˆ‘ä»¬å†ç”¨å…¶ä»–çš„æ¨¡å‹çš„æ—¶å€™ï¼Œåªéœ€è¦ç»§æ‰¿è¿™ä¸ªåŸºç±»ï¼Œç„¶ååœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œä¿®æ”¹å³å¯ï¼Œæ–¹ä¾¿ä»£ç æ‰©å±•ã€‚

```python
class BaseEmbeddings:
    """
    Base class for embeddings
    """
    def __init__(self, path: str, is_api: bool) -> None:
        self.path = path
        self.is_api = is_api
    
    def get_embedding(self, text: str, model: str) -> List[float]:
        raise NotImplementedError
    
    @classmethod
    def cosine_similarity(cls, vector1: List[float], vector2: List[float]) -> float:
        """
        calculate cosine similarity between two vectors
        """
        dot_product = np.dot(vector1, vector2)
        magnitude = np.linalg.norm(vector1) * np.linalg.norm(vector2)
        if not magnitude:
            return 0
        return dot_product / magnitude
```

è§‚å¯Ÿä¸€ä¸‹`BaseEmbeddings`åŸºç±»éƒ½æœ‰ä»€ä¹ˆæ–¹æ³•ï¼Œé¦–å…ˆæœ‰ä¸€ä¸ª`get_embedding`æ–¹æ³•ï¼Œè¿™ä¸ªæ–¹æ³•æ˜¯ç”¨æ¥è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤ºçš„ï¼Œç„¶åæœ‰ä¸€ä¸ª`cosine_similarity`æ–¹æ³•ï¼Œè¿™ä¸ªæ–¹æ³•æ˜¯ç”¨æ¥è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦çš„ã€‚å…¶æ¬¡åœ¨åˆå§‹åŒ–ç±»çš„æ—¶å€™è®¾ç½®äº†ï¼Œæ¨¡å‹çš„è·¯å¾„å’Œæ˜¯å¦æ˜¯APIæ¨¡å‹ã€‚æ¯”å¦‚ä½¿ç”¨OpenAIçš„Embedding APIçš„è¯å°±éœ€è¦è®¾ç½®`self.is_api=Ture`ã€‚

ç»§æ‰¿`BaseEmbeddings`ç±»çš„è¯ï¼Œå°±åªéœ€è¦ç¼–å†™`get_embedding`æ–¹æ³•å³å¯ï¼Œ`cosine_similarity`æ–¹æ³•ä¼šè¢«ç»§æ‰¿ä¸‹æ¥ï¼Œç›´æ¥ç”¨å°±è¡Œã€‚è¿™å°±æ˜¯ç¼–å†™åŸºç±»çš„å¥½å¤„ã€‚

```python
class OpenAIEmbedding(BaseEmbeddings):
    """
    class for OpenAI embeddings
    """
    def __init__(self, path: str = '', is_api: bool = True) -> None:
        super().__init__(path, is_api)
        if self.is_api:
            from openai import OpenAI
            self.client = OpenAI()
            self.client.api_key = os.getenv("OPENAI_API_KEY")
            self.client.base_url = os.getenv("OPENAI_BASE_URL")
    
    def get_embedding(self, text: str, model: str = "text-embedding-3-large") -> List[float]:
        if self.is_api:
            text = text.replace("\n", " ")
            return self.client.embeddings.create(input=[text], model=model).data[0].embedding
        else:
            raise NotImplementedError
```

## 3. æ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†

æ¥ä¸‹æ¥æˆ‘ä»¬æ¥å®ç°ä¸€ä¸ªæ–‡æ¡£åŠ è½½å’Œåˆ‡åˆ†çš„ç±»ï¼Œè¿™ä¸ªç±»ä¸»è¦æ˜¯ç”¨æ¥åŠ è½½æ–‡æ¡£å¹¶åˆ‡åˆ†æˆæ–‡æ¡£ç‰‡æ®µã€‚

é‚£æˆ‘ä»¬éƒ½éœ€è¦åˆ‡åˆ†ä»€ä¹ˆæ–‡æ¡£å‘¢ï¼Ÿè¿™ä¸ªæ–‡æ¡£å¯ä»¥æ˜¯ä¸€ç¯‡æ–‡ç« ï¼Œä¸€æœ¬ä¹¦ï¼Œä¸€æ®µå¯¹è¯ï¼Œä¸€æ®µä»£ç ç­‰ç­‰ã€‚è¿™ä¸ªæ–‡æ¡£çš„å†…å®¹å¯ä»¥æ˜¯ä»»ä½•çš„ï¼Œåªè¦æ˜¯æ–‡æœ¬å°±è¡Œã€‚æ¯”å¦‚ï¼špdfæ–‡ä»¶ã€mdæ–‡ä»¶ã€txtæ–‡ä»¶ç­‰ç­‰ã€‚

è¿™é‡Œåªå±•ç¤ºä¸€éƒ¨åˆ†å†…å®¹äº†ï¼Œå®Œæ•´çš„ä»£ç å¯ä»¥åœ¨ ***[RAG/utils.py](./RAG/utils.py)*** æ–‡ä»¶ä¸­æ‰¾åˆ°ã€‚åœ¨è¿™ä¸ªä»£ç ä¸­å¯ä»¥çœ‹åˆ°ï¼Œèƒ½åŠ è½½çš„æ–‡ä»¶ç±»å‹æœ‰ï¼špdfã€mdã€txtï¼Œåªéœ€è¦ç¼–å†™å¯¹åº”çš„å‡½æ•°å³å¯ã€‚

```python
def read_file_content(cls, file_path: str):
    # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è¯»å–æ–¹æ³•
    if file_path.endswith('.pdf'):
        return cls.read_pdf(file_path)
    elif file_path.endswith('.md'):
        return cls.read_markdown(file_path)
    elif file_path.endswith('.txt'):
        return cls.read_text(file_path)
    else:
        raise ValueError("Unsupported file type")
```

é‚£æˆ‘ä»¬æŠŠæ–‡ä»¶å†…å®¹éƒ½è¯»å–ä¹‹åï¼Œè¿˜éœ€è¦åˆ‡åˆ†å‘€ï¼é‚£æ€ä¹ˆåˆ‡åˆ†å‘¢ï¼ŒOKï¼Œæ¥ä¸‹æ¥å’±ä»¬å°±æŒ‰ Token çš„é•¿åº¦æ¥åˆ‡åˆ†æ–‡æ¡£ã€‚æˆ‘ä»¬å¯ä»¥è®¾ç½®ä¸€ä¸ªæœ€å¤§çš„ Token é•¿åº¦ï¼Œç„¶åæ ¹æ®è¿™ä¸ªæœ€å¤§çš„ Token é•¿åº¦æ¥åˆ‡åˆ†æ–‡æ¡£ã€‚è¿™æ ·åˆ‡åˆ†å‡ºæ¥çš„æ–‡æ¡£ç‰‡æ®µå°±æ˜¯ä¸€ä¸ªä¸€ä¸ªçš„å·®ä¸å¤šç›¸åŒé•¿åº¦çš„æ–‡æ¡£ç‰‡æ®µäº†ã€‚

ä¸è¿‡åœ¨åˆ‡åˆ†çš„æ—¶å€™è¦æ³¨æ„ï¼Œç‰‡æ®µä¸ç‰‡æ®µä¹‹é—´æœ€å¥½è¦æœ‰ä¸€äº›é‡å çš„å†…å®¹ï¼Œè¿™æ ·æ‰èƒ½ä¿è¯æ£€ç´¢çš„æ—¶å€™èƒ½å¤Ÿæ£€ç´¢åˆ°ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚è¿˜æœ‰å°±æ˜¯åˆ‡åˆ†æ–‡æ¡£çš„æ—¶å€™æœ€å¥½ä»¥å¥å­ä¸ºå•ä½ï¼Œä¹Ÿå°±æ˜¯æŒ‰ `\n` è¿›è¡Œç²—åˆ‡åˆ†ï¼Œè¿™æ ·å¯ä»¥åŸºæœ¬ä¿è¯å¥å­å†…å®¹æ˜¯å®Œæ•´çš„ã€‚

```python
def get_chunk(cls, text: str, max_token_len: int = 600, cover_content: int = 150):
    chunk_text = []

    curr_len = 0
    curr_chunk = ''

    lines = text.split('\n')  # å‡è®¾ä»¥æ¢è¡Œç¬¦åˆ†å‰²æ–‡æœ¬ä¸ºè¡Œ

    for line in lines:
        line = line.replace(' ', '')
        line_len = len(enc.encode(line))
        if line_len > max_token_len:
            print('warning line_len = ', line_len)
        if curr_len + line_len <= max_token_len:
            curr_chunk += line
            curr_chunk += '\n'
            curr_len += line_len
            curr_len += 1
        else:
            chunk_text.append(curr_chunk)
            curr_chunk = curr_chunk[-cover_content:]+line
            curr_len = line_len + cover_content

    if curr_chunk:
        chunk_text.append(curr_chunk)

    return chunk_text
```

## 4. æ•°æ®åº“ && å‘é‡æ£€ç´¢

ä¸Šé¢ï¼Œæˆ‘ä»¬åšå¥½äº†æ–‡æ¡£åˆ‡åˆ†ï¼Œä¹Ÿåšå¥½äº† Embedding æ¨¡å‹çš„åŠ è½½ã€‚é‚£æ¥ä¸‹æ¥å°±å¾—è®¾è®¡ä¸€ä¸ªå‘é‡æ•°æ®åº“ç”¨æ¥å­˜æ”¾æ–‡æ¡£ç‰‡æ®µå’Œå¯¹åº”çš„å‘é‡è¡¨ç¤ºäº†ã€‚

è¿˜æœ‰å°±æ˜¯ä¹Ÿè¦è®¾è®¡ä¸€ä¸ªæ£€ç´¢æ¨¡å—ï¼Œç”¨æ¥æ ¹æ® Query ï¼ˆé—®é¢˜ï¼‰æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚OKï¼Œæˆ‘ä»¬å†²å†²å†²ï¼

ä¸€ä¸ªæ•°æ®åº“å¯¹äºæœ€å°RAGæ¶æ„æ¥è¯´ï¼Œéœ€è¦å®ç°å‡ ä¸ªåŠŸèƒ½å‘¢ï¼Ÿ

- `persist`ï¼šæ•°æ®åº“æŒä¹…åŒ–ï¼Œæœ¬åœ°ä¿å­˜
- `load_vector`ï¼šä»æœ¬åœ°åŠ è½½æ•°æ®åº“
- `get_vector`ï¼šè·å¾—æ–‡æ¡£çš„å‘é‡è¡¨ç¤º
- `query`ï¼šæ ¹æ®é—®é¢˜æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ

ä»¥ä¸Šå››ä¸ªæ¨¡å—å°±æ˜¯ä¸€ä¸ªæœ€å°çš„RAGç»“æ„æ•°æ®åº“éœ€è¦å®ç°çš„åŠŸèƒ½ï¼Œå…·ä½“ä»£ç å¯ä»¥åœ¨ ***[RAG/VectorBase.py](./RAG/VectorBase.py)*** æ–‡ä»¶ä¸­æ‰¾åˆ°ã€‚

```python
class VectorStore:
    def __init__(self, document: List[str] = ['']) -> None:
        self.document = document

    def get_vector(self, EmbeddingModel: BaseEmbeddings) -> List[List[float]]:
        # è·å¾—æ–‡æ¡£çš„å‘é‡è¡¨ç¤º
        pass

    def persist(self, path: str = 'storage'):
        # æ•°æ®åº“æŒä¹…åŒ–ï¼Œæœ¬åœ°ä¿å­˜
        pass

    def load_vector(self, path: str = 'storage'):
        # ä»æœ¬åœ°åŠ è½½æ•°æ®åº“
        pass

    def query(self, query: str, EmbeddingModel: BaseEmbeddings, k: int = 1) -> List[str]:
        # æ ¹æ®é—®é¢˜æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
        pass
```

é‚£è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ï¼Œ `query` æ–¹æ³•å…·ä½“æ˜¯æ€ä¹ˆå®ç°çš„å‘¢ï¼Ÿ

é¦–å…ˆå…ˆæŠŠç”¨æˆ·æå‡ºçš„é—®é¢˜å‘é‡åŒ–ï¼Œç„¶åå»æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µï¼Œæœ€åè¿”å›æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µã€‚å¯ä»¥çœ‹åˆ°å’±ä»¬åœ¨å‘é‡æ£€ç´¢çš„æ—¶å€™ä»…ä½¿ç”¨ `Numpy` è¿›è¡ŒåŠ é€Ÿï¼Œä»£ç éå¸¸å®¹æ˜“ç†è§£å’Œä¿®æ”¹ã€‚

ä¸»è¦æ˜¯æ–¹ä¾¿æ”¹å†™å’Œå¤§å®¶ç†è§£ï¼Œå¹¶æ²¡æœ‰ä½¿ç”¨æˆç†Ÿçš„æ•°æ®åº“ï¼Œè¿™æ ·å¯ä»¥æ›´å¥½çš„ç†è§£RAGçš„åŸç†ã€‚

```python
def query(self, query: str, EmbeddingModel: BaseEmbeddings, k: int = 1) -> List[str]:
    query_vector = EmbeddingModel.get_embedding(query)
    result = np.array([self.get_similarity(query_vector, vector)
                        for vector in self.vectors])
    return np.array(self.document)[result.argsort()[-k:][::-1]].tolist()
```


## 5. å¤§æ¨¡å‹æ¨¡å—

é‚£å°±æ¥åˆ°äº†æœ€åä¸€ä¸ªæ¨¡å—äº†ï¼Œå¤§æ¨¡å‹æ¨¡å—ã€‚è¿™ä¸ªæ¨¡å—ä¸»è¦æ˜¯ç”¨æ¥æ ¹æ®æ£€ç´¢å‡ºæ¥çš„æ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

ä¸€æ ·çš„ï¼Œæˆ‘ä»¬è¿˜æ˜¯å…ˆå®ç°ä¸€ä¸ªåŸºç±»ï¼Œè¿™æ ·æˆ‘ä»¬åœ¨é‡åˆ°å…¶ä»–çš„è‡ªå·±æ„Ÿå…´è¶£çš„æ¨¡å‹å°±å¯ä»¥å¿«é€Ÿçš„æ‰©å±•äº†ã€‚

```python
class BaseModel:
    def __init__(self, path: str = '') -> None:
        self.path = path

    def chat(self, prompt: str, history: List[dict], content: str) -> str:
        pass

    def load_model(self):
        pass
```

`BaseModel` åŒ…å«äº†ä¸¤ä¸ªæ–¹æ³•ï¼Œ`chat`å’Œ`load_model`ï¼Œå¦‚æœä½¿ç”¨APIæ¨¡å‹ï¼Œæ¯”å¦‚OpenAIçš„è¯ï¼Œé‚£å°±ä¸éœ€è¦`load_model`æ–¹æ³•ï¼Œå¦‚æœä½ è¦æœ¬åœ°åŒ–è¿è¡Œçš„è¯ï¼Œé‚£è¿˜æ˜¯ä¼šé€‰æ‹©ä½¿ç”¨å¼€æºæ¨¡å‹ï¼Œé‚£å°±éœ€è¦`load_model`æ–¹æ³•ã€‚

ä»¥ ***[InternLM2-chat-7B](https://huggingface.co/internlm/internlm2-chat-7b)*** æ¨¡å‹ä¸ºä¾‹

```python
class InternLMChat(BaseModel):
    def __init__(self, path: str = '') -> None:
        super().__init__(path)
        self.load_model()

    def chat(self, prompt: str, history: List = [], content: str='') -> str:
        prompt = PROMPT_TEMPLATE['InternLM_PROMPT_TEMPALTE'].format(question=prompt, context=content)
        response, history = self.model.chat(self.tokenizer, prompt, history)
        return response


    def load_model(self):
        import torch
        from transformers import AutoTokenizer, AutoModelForCausalLM
        self.tokenizer = AutoTokenizer.from_pretrained(self.path, trust_remote_code=True)
        self.model = AutoModelForCausalLM.from_pretrained(self.path, torch_dtype=torch.float16, trust_remote_code=True).cuda()
```

å¯ä»¥ç”¨ä¸€ä¸ªå­—å…¸æ¥ä¿å­˜æ‰€æœ‰çš„promptï¼Œè¿™æ ·æ¯”è¾ƒå¥½ç»´æŠ¤ã€‚

```python
PROMPT_TEMPLATE = dict(
    InternLM_PROMPT_TEMPALTE="""å…ˆå¯¹ä¸Šä¸‹æ–‡è¿›è¡Œå†…å®¹æ€»ç»“,å†ä½¿ç”¨ä¸Šä¸‹æ–‡æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“ã€‚æ€»æ˜¯ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚
        é—®é¢˜: {question}
        å¯å‚è€ƒçš„ä¸Šä¸‹æ–‡ï¼š
        Â·Â·Â·
        {context}
        Â·Â·Â·
        å¦‚æœç»™å®šçš„ä¸Šä¸‹æ–‡æ— æ³•è®©ä½ åšå‡ºå›ç­”ï¼Œè¯·å›ç­”æ•°æ®åº“ä¸­æ²¡æœ‰è¿™ä¸ªå†…å®¹ï¼Œä½ ä¸çŸ¥é“ã€‚
        æœ‰ç”¨çš„å›ç­”:"""
)
```

é‚£è¿™æ ·çš„è¯ï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨InternLM2æ¨¡å‹æ¥åšRAGï¼

## 6.  LLM Tiny-RAG Demo

é‚£æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±æ¥çœ‹ä¸€ä¸‹Tiny-RAGçš„Demoå§ï¼

```python
from RAG.VectorBase import VectorStore
from RAG.utils import ReadFiles
from RAG.LLM import OpenAIChat, InternLMChat
from RAG.Embeddings import JinaEmbedding, ZhipuEmbedding


# æ²¡æœ‰ä¿å­˜æ•°æ®åº“
docs = ReadFiles('./data').get_content(max_token_len=600, cover_content=150) # è·å¾—dataç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å†…å®¹å¹¶åˆ†å‰²
vector = VectorStore(docs)
embedding = ZhipuEmbedding() # åˆ›å»ºEmbeddingModel
vector.get_vector(EmbeddingModel=embedding)
vector.persist(path='storage') # å°†å‘é‡å’Œæ–‡æ¡£å†…å®¹ä¿å­˜åˆ°storageç›®å½•ä¸‹ï¼Œä¸‹æ¬¡å†ç”¨å°±å¯ä»¥ç›´æ¥åŠ è½½æœ¬åœ°çš„æ•°æ®åº“

question = 'gitçš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ'

content = vector.query(question, model='zhipu', k=1)[0]
chat = InternLMChat(path='model_path')
print(chat.chat(question, [], content))
```

å½“ç„¶æˆ‘ä»¬ä¹Ÿå¯ä»¥ä»æœ¬åœ°åŠ è½½å·²ç»å¤„ç†å¥½çš„æ•°æ®åº“ï¼Œæ¯•ç«Ÿæˆ‘ä»¬åœ¨ä¸Šé¢çš„æ•°æ®åº“ç¯èŠ‚å·²ç»å†™è¿‡è¿™ä¸ªåŠŸèƒ½ã€‚

```python
from RAG.VectorBase import VectorStore
from RAG.utils import ReadFiles
from RAG.LLM import OpenAIChat, InternLMChat
from RAG.Embeddings import JinaEmbedding, ZhipuEmbedding

# ä¿å­˜æ•°æ®åº“ä¹‹å
vector = VectorStore()

vector.load_vector('./storage') # åŠ è½½æœ¬åœ°çš„æ•°æ®åº“

question = 'gitçš„åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ'

embedding = ZhipuEmbedding() # åˆ›å»ºEmbeddingModel

content = vector.query(question, EmbeddingModel=embedding, k=1)[0]
chat = InternLMChat(path='model_path')
print(chat.chat(question, [], content))
```

## 7. æ€»ç»“

æœ€åç”¨ä¸¤å¼ å›¾æ¥æ€»ç»“RAGï¼š

é€šè¿‡æ„å»º LLM å­ªç”Ÿï¼Œä¸º LLM ç³»ç»Ÿæä¾›ç«¯åˆ°ç«¯æ¡†æ¶ï¼š

An end-to-end framework for production-ready LLM systems by building your LLM twinï¼ŒLLM_twin_system_architecture

![](https://cdn.jsdelivr.net/gh/HuZixia/CloudGo/pictures/resources/rag/LLM_twin_system_architecture.png)



é«˜çº§æ£€ç´¢å¢å¼ºç”Ÿæˆ ï¼ˆRAGï¼‰ï¼šæ£€ç´¢ Python æ¨¡å—æ¶æ„

Advanced Retrieval-Augmented Generation (RAG): Retrieval Python Module Architechture

Retrieval_Python_Module_Architecture

![](https://cdn.jsdelivr.net/gh/HuZixia/CloudGo/pictures/resources/rag/Retrieval_Python_Module_Architecture.png)


## 8. å‚è€ƒæ–‡çŒ®


- æ„Ÿè°¢DataWhaleç»„ç»‡çš„å¤§æ¨¡å‹å®æˆ˜å­¦ä¹ ï¼Œå¯¹åº”çš„githubé“¾æ¥ ğŸ”—ï¼š[tiny-universe](https://github.com/datawhalechina/tiny-universe)
- [When Large Language Models Meet Vector Databases: A Survey](http://arxiv.org/abs/2402.01763)
- [Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997)
- [Learning to Filter Context for Retrieval-Augmented Generation](http://arxiv.org/abs/2311.08377)
- [In-Context Retrieval-Augmented Language Models](https://arxiv.org/abs/2302.00083)

